import cv2
import torch
import numpy as np
from PIL import Image
from facenet_pytorch import MTCNN, InceptionResnetV1
from sklearn.metrics.pairwise import cosine_similarity
import mysql.connector
from datetime import datetime
from utils.fake_detector import texture_score

# ===============================
# 1Ô∏è‚É£ C·∫§U H√åNH M√îI TR∆Ø·ªúNG
# ===============================
device = 'cuda' if torch.cuda.is_available() else 'cpu'
mtcnn = MTCNN(keep_all=True, device=device)
arcface_model = InceptionResnetV1(pretrained='vggface2').eval().to(device)

print(f"üß† Device: {device}")

# ===============================
# 2Ô∏è‚É£ K·∫æT N·ªêI C∆† S·ªû D·ªÆ LI·ªÜU
# ===============================
def get_connection():
    return mysql.connector.connect(
        host="localhost",
        user="root",
        password="",
        database="face_attendance"
    )

# ===============================
# 3Ô∏è‚É£ PH√ÅT HI·ªÜN VI·ªÄN M√ÄN H√åNH (FAKE)
# ===============================
def detect_border_or_screen(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 80, 150)
    h, w = gray.shape
    border_ratio = (
        np.mean(edges[:int(0.05*h), :]) +
        np.mean(edges[-int(0.05*h):, :]) +
        np.mean(edges[:, :int(0.05*w)]) +
        np.mean(edges[:, -int(0.05*w):])
    ) / 4
    contrast = gray.std()
    return border_ratio > 20 or contrast < 30

# ===============================
# 4Ô∏è‚É£ TR√çCH XU·∫§T VECTOR ARC_FACE
# ===============================
def extract_arcface_embedding(frame):
    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    face_tensor = mtcnn(img)
    if face_tensor is None:
        return None
    with torch.no_grad():
        embeddings = arcface_model(face_tensor.to(device)).cpu().numpy()
    return embeddings[0] if len(embeddings) > 0 else None

# ===============================
# 5Ô∏è‚É£ GHI ƒêI·ªÇM DANH V√ÄO DB
# ===============================
def mark_attendance(student_id):
    conn = get_connection()
    cur = conn.cursor()
    cur.execute("SELECT StudyID FROM study WHERE StudentID = %s LIMIT 1", (student_id,))
    result = cur.fetchone()

    if not result:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y StudyID cho StudentID:", student_id)
        return

    study_id = result[0]
    now = datetime.now()
    photo_path = f"photos/{student_id}_{now.strftime('%Y%m%d_%H%M%S')}.jpg"

    cur.execute("""
        INSERT INTO attendance (StudyID, StudentID, Date, Time, PhotoPath)
        VALUES (%s, %s, CURDATE(), CURTIME(), %s)
    """, (study_id, student_id, photo_path))
    conn.commit()
    cur.close()
    conn.close()
    print(f"‚úÖ ƒê√£ ghi ƒëi·ªÉm danh cho StudentID={student_id}")

# ===============================
# 6Ô∏è‚É£ NH·∫¨N DI·ªÜN V√Ä GHI DANH
# ===============================
def check_real_fake_from_camera(known_faces, known_ids):
    cap = cv2.VideoCapture(0)
    print("üé• Camera ƒëang m·ªü... Nh·∫•n 'q' ƒë·ªÉ tho√°t.")

    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ùå Kh√¥ng th·ªÉ truy c·∫≠p camera.")
            break

        label = "ƒêang ki·ªÉm tra..."
        color = (255, 255, 255)

        if detect_border_or_screen(frame):
            label = "‚ùå FAKE (BORDER)"
            color = (0, 0, 255)
        else:
            img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            tscore = texture_score(img_pil)

            if tscore < 0.5:
                label = f"‚ùå FAKE ({tscore:.2f})"
                color = (0, 0, 255)
            else:
                emb = extract_arcface_embedding(frame)
                if emb is not None:
                    sims = cosine_similarity([emb], known_faces)[0]
                    best_idx = np.argmax(sims)
                    best_score = sims[best_idx]
                    best_id = known_ids[best_idx]

                    if best_score > 0.85:
                        label = f"‚úÖ ID={best_id} ({best_score:.3f})"
                        color = (0, 255, 0)
                        mark_attendance(best_id)
                    else:
                        label = f"‚ùå Kh√¥ng tr√πng (max={best_score:.2f})"
                        color = (0, 0, 255)
                else:
                    label = "‚ö†Ô∏è Kh√¥ng th·∫•y m·∫∑t"
                    color = (255, 255, 0)

        cv2.putText(frame, label, (30, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)
        cv2.imshow("Face Attendance", frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# ===============================
# 7Ô∏è‚É£ CH·∫†Y CH√çNH
# ===============================
if __name__ == "__main__":
    conn = get_connection()
    cur = conn.cursor()
    cur.execute("SELECT student_id, embedding FROM students WHERE embedding IS NOT NULL")
    rows = cur.fetchall()
    cur.close()
    conn.close()

    known_faces = []
    known_ids = []
    for sid, emb_blob in rows:
        emb = np.frombuffer(emb_blob, dtype=np.float32)
        known_faces.append(emb)
        known_ids.append(sid)

    known_faces = np.array(known_faces)
    print(f"‚úÖ ƒê√£ t·∫£i {len(known_ids)} embedding h·ª£p l·ªá t·ª´ MySQL.")
    check_real_fake_from_camera(known_faces, known_ids)
