import os
import pickle
import numpy as np
import cv2
from deepface import DeepFace
from tqdm import tqdm
import hashlib
from datetime import datetime
import random
from PIL import Image
import torch
from facenet_pytorch import MTCNN

# ===============================
# ‚öôÔ∏è C·∫§U H√åNH
# ===============================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATASET_PATH = os.path.join(BASE_DIR, "..", "data", "face")
OUTPUT_DIR = os.path.join(BASE_DIR, "..", "models")
os.makedirs(OUTPUT_DIR, exist_ok=True)

FACE_VARIANCE_THRESHOLD = 120  # Ng∆∞·ª°ng ph√°t hi·ªán ·∫£nh m·ªù

print("üöÄ ƒêang kh·ªüi t·∫°o ArcFace + MTCNN (th·ªß c√¥ng)...")

MODEL_NAME = "ArcFace"

# ‚úÖ Kh·ªüi t·∫°o model ArcFace m·ªôt l·∫ßn ƒë·ªÉ cache
model = DeepFace.build_model(MODEL_NAME)

# ‚úÖ Kh·ªüi t·∫°o MTCNN th·ªß c√¥ng
device = 'cuda' if torch.cuda.is_available() else 'cpu'
mtcnn = MTCNN(keep_all=True, device=device)
print(f"‚úÖ MTCNN th·ªß c√¥ng kh·ªüi t·∫°o tr√™n {device}")


# ===============================
# üß© H√ÄM H·ªñ TR·ª¢
# ===============================
def hash_image(img_path):
    """Sinh hash duy nh·∫•t cho ·∫£nh"""
    with open(img_path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()


def is_blurry(img):
    """Ki·ªÉm tra ·∫£nh c√≥ b·ªã m·ªù kh√¥ng"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return cv2.Laplacian(gray, cv2.CV_64F).var() < FACE_VARIANCE_THRESHOLD

def extract_face_embedding(image_path):
    """Ph√°t hi·ªán + tr√≠ch xu·∫•t embedding khu√¥n m·∫∑t (ArcFace + MTCNN th·ªß c√¥ng)"""
    try:
        img = cv2.imread(image_path)
        if img is None or is_blurry(img):
            return None

        # Chuy·ªÉn sang RGB cho MTCNN
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # ‚úÖ Ph√°t hi·ªán khu√¥n m·∫∑t
        boxes, _ = mtcnn.detect(img_rgb)
        if boxes is None or len(boxes) == 0:
            return None

        # C·∫Øt khu√¥n m·∫∑t ƒë·∫ßu ti√™n
        x1, y1, x2, y2 = [int(v) for v in boxes[0]]
        face = img_rgb[y1:y2, x1:x2]

        # N·∫øu kh√¥ng c·∫Øt ƒë∆∞·ª£c m·∫∑t
        if face.size == 0:
            return None

        # ‚úÖ Chuy·ªÉn ƒë√∫ng dtype v√† ƒë·ªãnh d·∫°ng
        face = np.array(face, dtype=np.uint8)

        # ‚úÖ Tr√≠ch xu·∫•t embedding tr·ª±c ti·∫øp b·∫±ng m·∫£ng numpy (kh√¥ng d√πng img_path)
        result = DeepFace.represent(
            img_path=face,
            model_name=MODEL_NAME,
            enforce_detection=False
        )

        if result and len(result) > 0:
            embedding = np.array(result[0]["embedding"], dtype=np.float32)
            norm = np.linalg.norm(embedding)
            if norm == 0:
                return None
            embedding /= norm  # chu·∫©n h√≥a vector
            return embedding

        return None

    except Exception as e:
        print(f"‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c embedding: {e}")
        return None


# ===============================
# üîÄ CHIA TRAIN / TEST
# ===============================
def split_people(dataset_path, test_ratio=0.2):
    people = [p for p in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, p))]
    random.shuffle(people)
    n_test = max(1, int(len(people) * test_ratio))
    return set(people[n_test:]), set(people[:n_test])


# ===============================
# üß† T·∫†O EMBEDDING
# ===============================
def generate_embeddings(people_list):
    encodings, names, hashes = [], [], []
    total_faces, skipped = 0, 0

    for person_name in sorted(people_list):
        person_folder = os.path.join(DATASET_PATH, person_name)
        if not os.path.isdir(person_folder):
            continue

        print(f"\nüßç Ng∆∞·ªùi: {person_name}")
        for image_name in tqdm(sorted(os.listdir(person_folder))):
            if not image_name.lower().endswith((".jpg", ".png", ".jpeg")):
                continue

            image_path = os.path.join(person_folder, image_name)
            emb = extract_face_embedding(image_path)
            if emb is None:
                skipped += 1
                continue

            encodings.append(emb)
            names.append(person_name)
            hashes.append(hash_image(image_path))
            total_faces += 1

    return encodings, names, hashes, total_faces, skipped


# ===============================
# üéØ CH·∫†Y CH√çNH
# ===============================
def main():
    print("\nüîπ T·∫†O EMBEDDING KHU√îN M·∫∂T (ArcFace + MTCNN th·ªß c√¥ng)\n")

    train_people, test_people = split_people(DATASET_PATH, test_ratio=0.2)
    print(f"üß© Train: {len(train_people)} ng∆∞·ªùi | Test: {len(test_people)} ng∆∞·ªùi")

    for mode, people in [("train", train_people), ("test", test_people)]:
        print(f"\n===== üî∞ X·ª¨ L√ù {mode.upper()} =====")
        encodings, names, hashes, total_faces, skipped = generate_embeddings(people)

        output_path = os.path.join(OUTPUT_DIR, f"face_encodings_{mode}_deep_arcface.pkl")
        with open(output_path, "wb") as f:
            pickle.dump({
                "encodings": encodings,
                "names": names,
                "hashes": hashes,
                "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "num_people": len(set(names)),
                "num_embeddings": len(encodings),
                "avg_len_embedding": int(np.mean([len(e) for e in encodings]) if encodings else 0),
                "model": "DeepFace-ArcFace",
                "detector": "Manual-MTCNN"
            }, f)

        print(f"\n‚úÖ ƒê√£ l∆∞u: {output_path}")
        print(f"üìä ·∫¢nh h·ª£p l·ªá: {total_faces} | B·ªè qua: {skipped}")
        print(f"üë• S·ªë ng∆∞·ªùi: {len(set(names))}\n")

    print("\nüéØ Ho√†n t·∫•t! Embedding Deep-ArcFace (Manual MTCNN) ƒë√£ ƒë∆∞·ª£c sinh.\n")


if __name__ == "__main__":
    main()
